---
license: apache-2.0
language: en
datasets: wikipedia
pipeline_tag: text-generation
---
## Model description
This is a LLaMA-like model with only 160M parameters trained on Wikipedia and part of the C4-en and C4-realnewslike datasets. 

No evaluation has been conducted yet, so use it with care.

Original source: `https://huggingface.co/JackFram/llama-160m`
